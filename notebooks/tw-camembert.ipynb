{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis using `camemBERT`\n",
    "\n",
    "`camemBERT` is a pre-trained version of `roBERTa` on french language data. The objective is to use pre-trained `camemBERT` to predict the polarity (positive or negative) of tweets. We only focus on model evaluation since we do not have labelled data. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from transformers import CamembertForSequenceClassification, CamembertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b453a9ba660476b89024fb8068375af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/811k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pemma\\OneDrive - GENES\\Ensae\\S1\\ML Python\\Projet\\twitter-inflation-perception\\env\\lib\\site-packages\\huggingface_hub\\file_download.py:127: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\pemma\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30914fa215624112805103bc4a2e76e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/508 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TOKENIZER = CamembertTokenizer.from_pretrained(\"camembert-base\", do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../backup/data/tweets_preprocessed.pkl\"\n",
    "with open(path, \"rb\") as f: \n",
    "    tweets_preprocessed = pkl.load(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict \n",
    "from transformers.models.camembert.modeling_camembert import CamembertForSequenceClassification\n",
    "\n",
    "\n",
    "def preprocess(tweets: List) -> Dict:\n",
    "    encoded_batch = TOKENIZER.batch_encode_plus(tweets,\n",
    "                                                truncation=True,\n",
    "                                                pad_to_max_length=True,\n",
    "                                                return_attention_mask=True,\n",
    "                                                return_tensors=\"pt\")\n",
    "    return encoded_batch[\"input_ids\"], encoded_batch[\"attention_mask\"]\n",
    "\n",
    "def predict(tweets: List, model):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        input_ids, attention_mask = preprocess(tweets)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        return outputs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at camembert-base were not used when initializing CamembertForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = CamembertForSequenceClassification.from_pretrained(\n",
    "    \"camembert-base\",\n",
    "    num_labels = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'training': False,\n",
       " '_parameters': OrderedDict(),\n",
       " '_buffers': OrderedDict(),\n",
       " '_non_persistent_buffers_set': set(),\n",
       " '_backward_hooks': OrderedDict(),\n",
       " '_is_full_backward_hook': None,\n",
       " '_forward_hooks': OrderedDict(),\n",
       " '_forward_pre_hooks': OrderedDict(),\n",
       " '_state_dict_hooks': OrderedDict(),\n",
       " '_load_state_dict_pre_hooks': OrderedDict(),\n",
       " '_load_state_dict_post_hooks': OrderedDict(),\n",
       " '_modules': OrderedDict([('roberta',\n",
       "               CamembertModel(\n",
       "                 (embeddings): CamembertEmbeddings(\n",
       "                   (word_embeddings): Embedding(32005, 768, padding_idx=1)\n",
       "                   (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "                   (token_type_embeddings): Embedding(1, 768)\n",
       "                   (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                   (dropout): Dropout(p=0.1, inplace=False)\n",
       "                 )\n",
       "                 (encoder): CamembertEncoder(\n",
       "                   (layer): ModuleList(\n",
       "                     (0): CamembertLayer(\n",
       "                       (attention): CamembertAttention(\n",
       "                         (self): CamembertSelfAttention(\n",
       "                           (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         )\n",
       "                         (output): CamembertSelfOutput(\n",
       "                           (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                           (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         )\n",
       "                       )\n",
       "                       (intermediate): CamembertIntermediate(\n",
       "                         (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                         (intermediate_act_fn): GELUActivation()\n",
       "                       )\n",
       "                       (output): CamembertOutput(\n",
       "                         (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                         (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       )\n",
       "                     )\n",
       "                     (1): CamembertLayer(\n",
       "                       (attention): CamembertAttention(\n",
       "                         (self): CamembertSelfAttention(\n",
       "                           (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         )\n",
       "                         (output): CamembertSelfOutput(\n",
       "                           (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                           (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         )\n",
       "                       )\n",
       "                       (intermediate): CamembertIntermediate(\n",
       "                         (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                         (intermediate_act_fn): GELUActivation()\n",
       "                       )\n",
       "                       (output): CamembertOutput(\n",
       "                         (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                         (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       )\n",
       "                     )\n",
       "                     (2): CamembertLayer(\n",
       "                       (attention): CamembertAttention(\n",
       "                         (self): CamembertSelfAttention(\n",
       "                           (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         )\n",
       "                         (output): CamembertSelfOutput(\n",
       "                           (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                           (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         )\n",
       "                       )\n",
       "                       (intermediate): CamembertIntermediate(\n",
       "                         (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                         (intermediate_act_fn): GELUActivation()\n",
       "                       )\n",
       "                       (output): CamembertOutput(\n",
       "                         (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                         (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       )\n",
       "                     )\n",
       "                     (3): CamembertLayer(\n",
       "                       (attention): CamembertAttention(\n",
       "                         (self): CamembertSelfAttention(\n",
       "                           (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         )\n",
       "                         (output): CamembertSelfOutput(\n",
       "                           (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                           (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         )\n",
       "                       )\n",
       "                       (intermediate): CamembertIntermediate(\n",
       "                         (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                         (intermediate_act_fn): GELUActivation()\n",
       "                       )\n",
       "                       (output): CamembertOutput(\n",
       "                         (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                         (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       )\n",
       "                     )\n",
       "                     (4): CamembertLayer(\n",
       "                       (attention): CamembertAttention(\n",
       "                         (self): CamembertSelfAttention(\n",
       "                           (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         )\n",
       "                         (output): CamembertSelfOutput(\n",
       "                           (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                           (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         )\n",
       "                       )\n",
       "                       (intermediate): CamembertIntermediate(\n",
       "                         (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                         (intermediate_act_fn): GELUActivation()\n",
       "                       )\n",
       "                       (output): CamembertOutput(\n",
       "                         (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                         (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       )\n",
       "                     )\n",
       "                     (5): CamembertLayer(\n",
       "                       (attention): CamembertAttention(\n",
       "                         (self): CamembertSelfAttention(\n",
       "                           (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         )\n",
       "                         (output): CamembertSelfOutput(\n",
       "                           (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                           (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         )\n",
       "                       )\n",
       "                       (intermediate): CamembertIntermediate(\n",
       "                         (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                         (intermediate_act_fn): GELUActivation()\n",
       "                       )\n",
       "                       (output): CamembertOutput(\n",
       "                         (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                         (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       )\n",
       "                     )\n",
       "                     (6): CamembertLayer(\n",
       "                       (attention): CamembertAttention(\n",
       "                         (self): CamembertSelfAttention(\n",
       "                           (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         )\n",
       "                         (output): CamembertSelfOutput(\n",
       "                           (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                           (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         )\n",
       "                       )\n",
       "                       (intermediate): CamembertIntermediate(\n",
       "                         (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                         (intermediate_act_fn): GELUActivation()\n",
       "                       )\n",
       "                       (output): CamembertOutput(\n",
       "                         (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                         (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       )\n",
       "                     )\n",
       "                     (7): CamembertLayer(\n",
       "                       (attention): CamembertAttention(\n",
       "                         (self): CamembertSelfAttention(\n",
       "                           (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         )\n",
       "                         (output): CamembertSelfOutput(\n",
       "                           (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                           (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         )\n",
       "                       )\n",
       "                       (intermediate): CamembertIntermediate(\n",
       "                         (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                         (intermediate_act_fn): GELUActivation()\n",
       "                       )\n",
       "                       (output): CamembertOutput(\n",
       "                         (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                         (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       )\n",
       "                     )\n",
       "                     (8): CamembertLayer(\n",
       "                       (attention): CamembertAttention(\n",
       "                         (self): CamembertSelfAttention(\n",
       "                           (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         )\n",
       "                         (output): CamembertSelfOutput(\n",
       "                           (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                           (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         )\n",
       "                       )\n",
       "                       (intermediate): CamembertIntermediate(\n",
       "                         (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                         (intermediate_act_fn): GELUActivation()\n",
       "                       )\n",
       "                       (output): CamembertOutput(\n",
       "                         (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                         (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       )\n",
       "                     )\n",
       "                     (9): CamembertLayer(\n",
       "                       (attention): CamembertAttention(\n",
       "                         (self): CamembertSelfAttention(\n",
       "                           (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         )\n",
       "                         (output): CamembertSelfOutput(\n",
       "                           (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                           (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         )\n",
       "                       )\n",
       "                       (intermediate): CamembertIntermediate(\n",
       "                         (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                         (intermediate_act_fn): GELUActivation()\n",
       "                       )\n",
       "                       (output): CamembertOutput(\n",
       "                         (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                         (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       )\n",
       "                     )\n",
       "                     (10): CamembertLayer(\n",
       "                       (attention): CamembertAttention(\n",
       "                         (self): CamembertSelfAttention(\n",
       "                           (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         )\n",
       "                         (output): CamembertSelfOutput(\n",
       "                           (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                           (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         )\n",
       "                       )\n",
       "                       (intermediate): CamembertIntermediate(\n",
       "                         (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                         (intermediate_act_fn): GELUActivation()\n",
       "                       )\n",
       "                       (output): CamembertOutput(\n",
       "                         (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                         (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       )\n",
       "                     )\n",
       "                     (11): CamembertLayer(\n",
       "                       (attention): CamembertAttention(\n",
       "                         (self): CamembertSelfAttention(\n",
       "                           (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         )\n",
       "                         (output): CamembertSelfOutput(\n",
       "                           (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                           (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         )\n",
       "                       )\n",
       "                       (intermediate): CamembertIntermediate(\n",
       "                         (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                         (intermediate_act_fn): GELUActivation()\n",
       "                       )\n",
       "                       (output): CamembertOutput(\n",
       "                         (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                         (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       )\n",
       "                     )\n",
       "                   )\n",
       "                 )\n",
       "               )),\n",
       "              ('classifier',\n",
       "               CamembertClassificationHead(\n",
       "                 (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                 (dropout): Dropout(p=0.1, inplace=False)\n",
       "                 (out_proj): Linear(in_features=768, out_features=3, bias=True)\n",
       "               ))]),\n",
       " 'config': CamembertConfig {\n",
       "   \"_name_or_path\": \"camembert-base\",\n",
       "   \"architectures\": [\n",
       "     \"CamembertForMaskedLM\"\n",
       "   ],\n",
       "   \"attention_probs_dropout_prob\": 0.1,\n",
       "   \"bos_token_id\": 5,\n",
       "   \"classifier_dropout\": null,\n",
       "   \"eos_token_id\": 6,\n",
       "   \"hidden_act\": \"gelu\",\n",
       "   \"hidden_dropout_prob\": 0.1,\n",
       "   \"hidden_size\": 768,\n",
       "   \"id2label\": {\n",
       "     \"0\": \"LABEL_0\",\n",
       "     \"1\": \"LABEL_1\",\n",
       "     \"2\": \"LABEL_2\"\n",
       "   },\n",
       "   \"initializer_range\": 0.02,\n",
       "   \"intermediate_size\": 3072,\n",
       "   \"label2id\": {\n",
       "     \"LABEL_0\": 0,\n",
       "     \"LABEL_1\": 1,\n",
       "     \"LABEL_2\": 2\n",
       "   },\n",
       "   \"layer_norm_eps\": 1e-05,\n",
       "   \"max_position_embeddings\": 514,\n",
       "   \"model_type\": \"camembert\",\n",
       "   \"num_attention_heads\": 12,\n",
       "   \"num_hidden_layers\": 12,\n",
       "   \"output_past\": true,\n",
       "   \"pad_token_id\": 1,\n",
       "   \"position_embedding_type\": \"absolute\",\n",
       "   \"transformers_version\": \"4.25.1\",\n",
       "   \"type_vocab_size\": 1,\n",
       "   \"use_cache\": true,\n",
       "   \"vocab_size\": 32005\n",
       " },\n",
       " 'name_or_path': 'camembert-base',\n",
       " 'warnings_issued': {},\n",
       " 'num_labels': 3,\n",
       " 'is_loaded_in_8bit': False}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.models.camembert.modeling_camembert.CamembertForSequenceClassification"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "tweets = tweets_preprocessed[\"cleaned_emojis\"]\n",
    "# selected = np.random.choice(tweets, size=10).tolist()\n",
    "\n",
    "selected = [\"J'aime les pâtes\", \"Il fait pas beau ici\", \"Je l'aime bien mais il sent pas très bon\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pemma\\OneDrive - GENES\\Ensae\\S1\\ML Python\\Projet\\twitter-inflation-perception\\env\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2336: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "predictions = predict(selected, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "from typing import Tuple \n",
    "from scipy.special import softmax\n",
    "\n",
    "LABELS = [\"Negative\", \"Positive\"]\n",
    "\n",
    "def transform_logits(logits: Tensor) -> np.ndarray: \n",
    "    \"\"\"Description. Transform logits to probabilitities using softmax.\"\"\"\n",
    "\n",
    "    scores = softmax(logits, axis=1)\n",
    "    return scores\n",
    "\n",
    "def get_sentiment(scores: np.ndarray) -> List: \n",
    "    \"\"\"Description. Get sentiment with highest probability.\"\"\"\n",
    "\n",
    "    return np.argmax(scores, axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = predictions.logits\n",
    "scores = transform_logits(logits)\n",
    "sentiments = get_sentiment(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet: J'aime les pâtes\n",
      "Sentiment: 0\n",
      "Scores=[0.51511437 0.48488557]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Tweet: Il fait pas beau ici\n",
      "Sentiment: 0\n",
      "Scores=[0.5043335  0.49566653]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Tweet: Je l'aime bien mais il sent pas très bon\n",
      "Sentiment: 0\n",
      "Scores=[0.5112664 0.4887336]\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(selected)): \n",
    "    print(f\"Tweet: {selected[i]}\")\n",
    "    print(f\"Sentiment: {sentiments[0]}\")\n",
    "    print(f\"Scores={scores[i]}\")\n",
    "    print(\"-\"*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4f0c75c3c98d859c17a8a7b8ea0d158e580de4be82cc7ea678b044820d2772f7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
