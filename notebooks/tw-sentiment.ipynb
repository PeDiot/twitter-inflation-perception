{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tI7zh8LxaZ6h"
      },
      "source": [
        "# Sentiment analysis using `camemBERT`\n",
        "\n",
        "`camemBERT` is a pre-trained version of `roBERTa` on french language data. The objective is to use pre-trained `camemBERT` to predict the polarity (positive or negative) of tweets. We only focus on model evaluation since we do not have labelled data. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2JUvy23aZ6r"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWm53M3Na1v_",
        "outputId": "84d0e811-a1e4-4556-91e0-ad1e52d09e95"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DRIVE_PATH = \"/content/drive/MyDrive/twitter-inflation-perception/\"\n",
        "\n",
        "import os\n",
        "os.chdir(DRIVE_PATH+\"notebooks/\")"
      ],
      "metadata": {
        "id": "YCBkqZ4Ub5c5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys \n",
        "sys.path.append(\"../\")"
      ],
      "metadata": {
        "id": "-OeigGHDue7P"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from lib.sentiment.preprocessing import (\n",
        "    load_tokenizer, \n",
        "    preprocess, \n",
        "    train_val_split\n",
        ")\n",
        "from lib.sentiment.model import load_model, backup_model \n",
        "\n",
        "from lib.sentiment.training import (\n",
        "    train, \n",
        "    init_scheduler, \n",
        "    check_convergence\n",
        ")\n",
        "from lib.sentiment.validation import evaluate \n",
        "\n",
        "from lib.sentiment.utils import results_to_dict, get_avg_training_losses"
      ],
      "metadata": {
        "id": "uoxk9Nixuh4o"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "DKTsS8qmHKM0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle as pkl\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "gTbgsyn2aZ6v"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import (\n",
        "    TensorDataset, \n",
        "    random_split, \n",
        "    DataLoader, \n",
        "    RandomSampler, \n",
        "    SequentialSampler\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install transformers==4.25.1"
      ],
      "metadata": {
        "id": "Bk3h7AfQbykY"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install sentencepiece"
      ],
      "metadata": {
        "id": "vSWgNVvLctyb"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AdamW"
      ],
      "metadata": {
        "id": "EU_g04Lmv4Oi"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data"
      ],
      "metadata": {
        "id": "di-jfnfAvB8D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "lvPWbsrRa9nJ"
      },
      "outputs": [],
      "source": [
        "file_path = DRIVE_PATH + \"backup/tweets/french_tweets.csv\"\n",
        "french_tweets = pd.read_csv(file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "3TqVX5esaZ6z",
        "outputId": "ba006341-4dc8-4d03-e9c1-2622bd7c1561"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   label                                               text\n",
              "0      0  - Awww, c'est un bummer. Tu devrais avoir davi...\n",
              "1      0  Est contrarié qu'il ne puisse pas mettre à jou...\n",
              "2      0  J'ai plongé plusieurs fois pour la balle. A ré...\n",
              "3      0  Tout mon corps a des démangeaisons et comme si...\n",
              "4      0  Non, il ne se comporte pas du tout. je suis en..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-98462a38-e200-470f-91f0-d73c017b3b5e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>- Awww, c'est un bummer. Tu devrais avoir davi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Est contrarié qu'il ne puisse pas mettre à jou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>J'ai plongé plusieurs fois pour la balle. A ré...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>Tout mon corps a des démangeaisons et comme si...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>Non, il ne se comporte pas du tout. je suis en...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-98462a38-e200-470f-91f0-d73c017b3b5e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-98462a38-e200-470f-91f0-d73c017b3b5e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-98462a38-e200-470f-91f0-d73c017b3b5e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "french_tweets.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u05Z3Z7uaZ61",
        "outputId": "ba2fe7ba-bacb-4114-c70b-daec4421a045"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1526724 tweets in the dataset\n"
          ]
        }
      ],
      "source": [
        "n_tweets, _ = french_tweets.shape\n",
        "print(f\"{n_tweets} tweets in the dataset\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLDj4BZnaZ63",
        "outputId": "6f21e0ce-cf01-46bd-bd87-40d5de855bfc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.505398\n",
              "1    0.494602\n",
              "Name: label, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "french_tweets[\"label\"].value_counts() / n_tweets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mk9hizUaZ64",
        "outputId": "76911dd6-369d-45d3-958a-8d6ac1056025"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "152672\n"
          ]
        }
      ],
      "source": [
        "# extract sample to reduce computation time \n",
        "\n",
        "prop = .1\n",
        "size = int(n_tweets * prop) \n",
        "idxs = np.random.randint(low=0, high=n_tweets, size=size).tolist()\n",
        "\n",
        "tweets_sample = french_tweets.iloc[idxs, :]\n",
        "\n",
        "print(len(tweets_sample))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmnXc80DaZ66",
        "outputId": "21a8434e-c4db-4ad8-8679-974044bd27d8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.505875\n",
              "1    0.494125\n",
              "Name: label, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "tweets_sample[\"label\"].value_counts() / len(tweets_sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "shklKqs4cCyT"
      },
      "outputs": [],
      "source": [
        "tweets = tweets_sample[\"text\"].values.tolist()\n",
        "sentiments = tweets_sample[\"label\"].values.tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpQwDmfaaZ67"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "3mywzDBYaZ68"
      },
      "outputs": [],
      "source": [
        "tokenizer = load_tokenizer()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxd-HGl5nSB0",
        "outputId": "5807334e-1e9b-4ca9-cd6c-2eaed2d1907d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "transformers.models.camembert.tokenization_camembert.CamembertTokenizer"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "cn4Ds-uIaZ6-"
      },
      "outputs": [],
      "source": [
        "tweets_train, tweets_validation, sentiments_train, sentiments_validation = train_val_split(tweets, sentiments, train_prop=.8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKSzqzMCaZ6_",
        "outputId": "76dea226-07bb-47e4-98ce-02d5c8e1ef5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:2336: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "input_ids, attention_mask, sentiments_train = preprocess(tweets_train, tokenizer, sentiments=sentiments_train)\n",
        "\n",
        "train_dataset = TensorDataset(\n",
        "    input_ids,\n",
        "    attention_mask,\n",
        "    sentiments_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "0r--v_RgaZ7A"
      },
      "outputs": [],
      "source": [
        "input_ids, attention_mask, sentiments_validation = preprocess(tweets_validation, tokenizer, sentiments=sentiments_validation)\n",
        "\n",
        "validation_dataset = TensorDataset(\n",
        "    input_ids,\n",
        "    attention_mask,\n",
        "    sentiments_validation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "KaIdMxlirdFc"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,\n",
        "            sampler = RandomSampler(train_dataset),\n",
        "            batch_size = batch_size)\n",
        "\n",
        "validation_dataloader = DataLoader(\n",
        "            validation_dataset,\n",
        "            sampler = SequentialSampler(validation_dataset),\n",
        "            batch_size = batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BfhGd_o-aZ7B"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYnFgb5kaZ7B"
      },
      "source": [
        "### Load `camemBERT`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fep4-kkXaZ7C",
        "outputId": "ba1621e9-0ad0-4949-f8b9-89a6a56434d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at camembert-base were not used when initializing CamembertForSequenceClassification: ['roberta.pooler.dense.bias', 'lm_head.layer_norm.bias', 'roberta.pooler.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n",
            "- This IS expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device=device(type='cuda', index=0)\n"
          ]
        }
      ],
      "source": [
        "model = load_model()\n",
        "\n",
        "# initialize a variable holding the device used for training ('cpu' or 'cuda')\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"{device=}\")\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3SD2aDfLaZ7D",
        "outputId": "3caef9cd-bf4c-470d-e38a-eacd4c680d79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "110,623,490 parameters in camemBERT\n"
          ]
        }
      ],
      "source": [
        "n_params = sum(p.numel() for p in model.parameters())\n",
        "print(\"{:,} parameters in camemBERT\".format(n_params) )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2AR19i7aZ7D"
      },
      "source": [
        "### Training & validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOv6aM1paZ7G",
        "outputId": "d424d2b1-32e1-4ba8-f056-e1582d83b02e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "statistics = []\n",
        "\n",
        "total_t0 = time.time()\n",
        "num_epochs = 5\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr = 2e-5, eps = 1e-8)\n",
        "scheduler = init_scheduler(num_epochs, train_dataloader, optimizer)\n",
        "\n",
        "model_path = \"../backup/models/twitter-camembert.pt\"\n",
        "\n",
        "# this variable will evaluate the convergence on the training\n",
        "consecutive_epochs_with_no_improve = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n99ypHFpaZ7H",
        "outputId": "217ee42a-5d8b-462f-cec8-c75107d0d9f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch [1/5]: 100%|██████████| 2/2 [00:01<00:00,  1.16it/s, loss_train=0.69, training_time=1.67e+9]\n",
            "Validation in progress: 100%|██████████| 2/2 [00:00<00:00,  7.98it/s, balanced_accuracy_score=0.52]\n",
            "Training Epoch [2/5]: 100%|██████████| 2/2 [00:01<00:00,  1.73it/s, loss_train=0.69, training_time=1.67e+9]\n",
            "Validation in progress: 100%|██████████| 2/2 [00:00<00:00,  8.28it/s, balanced_accuracy_score=0.5]\n",
            "Training Epoch [3/5]: 100%|██████████| 2/2 [00:01<00:00,  1.74it/s, loss_train=0.68, training_time=1.67e+9]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved at ../backup/models/twitter-camembert.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation in progress: 100%|██████████| 2/2 [00:00<00:00,  8.37it/s, balanced_accuracy_score=0.5]\n",
            "Training Epoch [4/5]: 100%|██████████| 2/2 [00:01<00:00,  1.72it/s, loss_train=0.68, training_time=1.67e+9]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved at ../backup/models/twitter-camembert.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation in progress: 100%|██████████| 2/2 [00:00<00:00,  8.43it/s, balanced_accuracy_score=0.5]\n",
            "Training Epoch [5/5]: 100%|██████████| 2/2 [00:01<00:00,  1.71it/s, loss_train=0.67, training_time=1.67e+9]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved at ../backup/models/twitter-camembert.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation in progress: 100%|██████████| 2/2 [00:00<00:00,  8.93it/s, balanced_accuracy_score=0.5]\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(num_epochs):\n",
        "    \n",
        "    batch_losses, training_times = train(\n",
        "        model, \n",
        "        train_dataloader, \n",
        "        device, \n",
        "        optimizer, \n",
        "        scheduler, \n",
        "        epoch, \n",
        "        num_epochs)\n",
        "\n",
        "    if num_epochs > 3 and epoch > 1: \n",
        "        curr_loss =  np.mean(batch_losses)\n",
        "        avg_train_losses = get_avg_training_losses(statistics)\n",
        "\n",
        "        consecutive_epochs_with_no_improve = check_convergence(\n",
        "            model, \n",
        "            model_path, \n",
        "            avg_train_losses, \n",
        "            curr_loss, \n",
        "            consecutive_epochs_with_no_improve)\n",
        "        \n",
        "        if consecutive_epochs_with_no_improve == 2:\n",
        "          print(\"Stop training: The loss has not changed since 2 epochs!\")\n",
        "          break\n",
        "\n",
        "    accuracy_scores = evaluate(model, validation_dataloader, device)\n",
        "    statistics.append(results_to_dict(epoch, batch_losses, training_times, accuracy_scores))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "wA76ASwfaZ7I"
      },
      "outputs": [],
      "source": [
        "training_stats_path = \"../backup/models/training-stats-camembert.json\"\n",
        "\n",
        "import json \n",
        "\n",
        "with open(training_stats_path, \"w\") as f:\n",
        "    json.dump(statistics, f) \n",
        "\n",
        "# backup_model(model, model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Geh_OXIaaZ7J"
      },
      "source": [
        "## Evaluation on unseen data"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "4f0c75c3c98d859c17a8a7b8ea0d158e580de4be82cc7ea678b044820d2772f7"
      }
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}